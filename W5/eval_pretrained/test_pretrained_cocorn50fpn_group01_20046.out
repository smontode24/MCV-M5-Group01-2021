Successfully registered 'ds_test'!
Dataset loaded...
Loading model pretrained weights...
[32m[03/26 17:16:02 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/26 17:16:46 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2642 images left.
[32m[03/26 17:16:46 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 3347         |  bicycle   | 0            |    car     | 8029         |
|            |              |            |              |            |              |
|   total    | 11376        |            |              |            |              |[0m
[32m[03/26 17:16:46 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/26 17:16:46 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/26 17:16:46 d2.data.common]: [0mSerializing 2642 elements to byte tensors and concatenating them all ...
[32m[03/26 17:16:51 d2.data.common]: [0mSerialized dataset takes 1039.45 MiB
Checkpoint loaded...
[32m[03/26 17:16:53 d2.evaluation.coco_evaluation]: [0m'ds_test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[5m[31mWARNING[0m [32m[03/26 17:16:53 d2.data.datasets.coco]: [0mUsing previously cached COCO format annotations at '/home/group01/W4_detectron2/pretrained/test_output/ds_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[32m[03/26 17:17:57 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/26 17:17:57 d2.data.common]: [0mSerializing 2642 elements to byte tensors and concatenating them all ...
[32m[03/26 17:18:01 d2.data.common]: [0mSerialized dataset takes 1039.45 MiB
[32m[03/26 17:18:03 d2.evaluation.evaluator]: [0mStart inference on 2642 images
[32m[03/26 17:18:05 d2.evaluation.evaluator]: [0mInference done 11/2642. 0.0541 s / img. ETA=0:03:01
[32m[03/26 17:18:10 d2.evaluation.evaluator]: [0mInference done 67/2642. 0.0582 s / img. ETA=0:03:45
[32m[03/26 17:18:15 d2.evaluation.evaluator]: [0mInference done 113/2642. 0.0602 s / img. ETA=0:04:04
[32m[03/26 17:18:20 d2.evaluation.evaluator]: [0mInference done 168/2642. 0.0599 s / img. ETA=0:03:54
[32m[03/26 17:18:25 d2.evaluation.evaluator]: [0mInference done 202/2642. 0.0717 s / img. ETA=0:04:18
[32m[03/26 17:18:30 d2.evaluation.evaluator]: [0mInference done 261/2642. 0.0684 s / img. ETA=0:04:01
[32m[03/26 17:18:35 d2.evaluation.evaluator]: [0mInference done 317/2642. 0.0665 s / img. ETA=0:03:50
[32m[03/26 17:18:40 d2.evaluation.evaluator]: [0mInference done 374/2642. 0.0653 s / img. ETA=0:03:41
[32m[03/26 17:18:45 d2.evaluation.evaluator]: [0mInference done 436/2642. 0.0640 s / img. ETA=0:03:29
[32m[03/26 17:18:50 d2.evaluation.evaluator]: [0mInference done 498/2642. 0.0633 s / img. ETA=0:03:20
[32m[03/26 17:18:56 d2.evaluation.evaluator]: [0mInference done 561/2642. 0.0625 s / img. ETA=0:03:11
[32m[03/26 17:19:01 d2.evaluation.evaluator]: [0mInference done 620/2642. 0.0623 s / img. ETA=0:03:04
[32m[03/26 17:19:06 d2.evaluation.evaluator]: [0mInference done 690/2642. 0.0617 s / img. ETA=0:02:54
[32m[03/26 17:19:11 d2.evaluation.evaluator]: [0mInference done 769/2642. 0.0607 s / img. ETA=0:02:42
[32m[03/26 17:19:16 d2.evaluation.evaluator]: [0mInference done 827/2642. 0.0608 s / img. ETA=0:02:37
[32m[03/26 17:19:21 d2.evaluation.evaluator]: [0mInference done 890/2642. 0.0606 s / img. ETA=0:02:30
[32m[03/26 17:19:26 d2.evaluation.evaluator]: [0mInference done 948/2642. 0.0609 s / img. ETA=0:02:26
[32m[03/26 17:19:31 d2.evaluation.evaluator]: [0mInference done 1023/2642. 0.0604 s / img. ETA=0:02:17
[32m[03/26 17:19:36 d2.evaluation.evaluator]: [0mInference done 1097/2642. 0.0601 s / img. ETA=0:02:09
[32m[03/26 17:19:41 d2.evaluation.evaluator]: [0mInference done 1130/2642. 0.0622 s / img. ETA=0:02:09
[32m[03/26 17:19:46 d2.evaluation.evaluator]: [0mInference done 1190/2642. 0.0620 s / img. ETA=0:02:04
[32m[03/26 17:19:51 d2.evaluation.evaluator]: [0mInference done 1251/2642. 0.0619 s / img. ETA=0:01:58
[32m[03/26 17:19:56 d2.evaluation.evaluator]: [0mInference done 1310/2642. 0.0618 s / img. ETA=0:01:53
[32m[03/26 17:20:01 d2.evaluation.evaluator]: [0mInference done 1372/2642. 0.0616 s / img. ETA=0:01:48
[32m[03/26 17:20:06 d2.evaluation.evaluator]: [0mInference done 1433/2642. 0.0614 s / img. ETA=0:01:42
[32m[03/26 17:20:11 d2.evaluation.evaluator]: [0mInference done 1502/2642. 0.0611 s / img. ETA=0:01:36
[32m[03/26 17:20:16 d2.evaluation.evaluator]: [0mInference done 1576/2642. 0.0608 s / img. ETA=0:01:29
[32m[03/26 17:20:21 d2.evaluation.evaluator]: [0mInference done 1653/2642. 0.0605 s / img. ETA=0:01:21
[32m[03/26 17:20:26 d2.evaluation.evaluator]: [0mInference done 1738/2642. 0.0600 s / img. ETA=0:01:13
[32m[03/26 17:20:31 d2.evaluation.evaluator]: [0mInference done 1796/2642. 0.0600 s / img. ETA=0:01:09
[32m[03/26 17:20:39 d2.evaluation.evaluator]: [0mInference done 1833/2642. 0.0603 s / img. ETA=0:01:08
[32m[03/26 17:20:44 d2.evaluation.evaluator]: [0mInference done 1874/2642. 0.0605 s / img. ETA=0:01:05
[32m[03/26 17:20:49 d2.evaluation.evaluator]: [0mInference done 1924/2642. 0.0606 s / img. ETA=0:01:01
[32m[03/26 17:20:54 d2.evaluation.evaluator]: [0mInference done 1976/2642. 0.0606 s / img. ETA=0:00:57
[32m[03/26 17:20:59 d2.evaluation.evaluator]: [0mInference done 2031/2642. 0.0606 s / img. ETA=0:00:52
[32m[03/26 17:21:04 d2.evaluation.evaluator]: [0mInference done 2098/2642. 0.0605 s / img. ETA=0:00:46
[32m[03/26 17:21:09 d2.evaluation.evaluator]: [0mInference done 2155/2642. 0.0605 s / img. ETA=0:00:41
[32m[03/26 17:21:14 d2.evaluation.evaluator]: [0mInference done 2202/2642. 0.0606 s / img. ETA=0:00:37
[32m[03/26 17:21:19 d2.evaluation.evaluator]: [0mInference done 2250/2642. 0.0607 s / img. ETA=0:00:33
[32m[03/26 17:21:24 d2.evaluation.evaluator]: [0mInference done 2296/2642. 0.0608 s / img. ETA=0:00:30
[32m[03/26 17:21:29 d2.evaluation.evaluator]: [0mInference done 2321/2642. 0.0609 s / img. ETA=0:00:28
[32m[03/26 17:21:34 d2.evaluation.evaluator]: [0mInference done 2386/2642. 0.0608 s / img. ETA=0:00:22
[32m[03/26 17:21:39 d2.evaluation.evaluator]: [0mInference done 2454/2642. 0.0606 s / img. ETA=0:00:16
[32m[03/26 17:21:44 d2.evaluation.evaluator]: [0mInference done 2512/2642. 0.0607 s / img. ETA=0:00:11
[32m[03/26 17:21:49 d2.evaluation.evaluator]: [0mInference done 2578/2642. 0.0606 s / img. ETA=0:00:05
[32m[03/26 17:21:54 d2.evaluation.evaluator]: [0mInference done 2636/2642. 0.0605 s / img. ETA=0:00:00
[32m[03/26 17:21:55 d2.evaluation.evaluator]: [0mTotal inference time: 0:03:51.038213 (0.087614 s / img per device, on 1 devices)
[32m[03/26 17:21:55 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:39 (0.060520 s / img per device, on 1 devices)
[32m[03/26 17:21:56 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/26 17:21:56 d2.evaluation.coco_evaluation]: [0mSaving results to /home/group01/W4_detectron2/pretrained/test_output/coco_instances_results.json
[32m[03/26 17:21:57 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.08s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 0.84 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.20 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.830
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.673
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.603
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.810
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[32m[03/26 17:21:58 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 58.753 | 82.974 | 67.293 | 60.336 | 69.984 | 43.652 |
[32m[03/26 17:21:58 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP   | category   | AP     |
|:-----------|:-------|:-----------|:-----|:-----------|:-------|
| person     | 47.615 | bicycle    | nan  | car        | 69.891 |
Loading and preparing results...
DONE (t=1.00s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 10.43 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.18 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[32m[03/26 17:22:16 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.001 | 0.006  | 0.000  | 0.000 | 0.003 | 0.000 |
[32m[03/26 17:22:16 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| person     | 0.000 | bicycle    | nan  | car        | 0.002 |
[32m[03/26 17:22:16 d2.engine.defaults]: [0mEvaluation results for ds_test in csv format:
[32m[03/26 17:22:16 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/26 17:22:16 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/26 17:22:16 d2.evaluation.testing]: [0mcopypaste: 58.7529,82.9742,67.2928,60.3358,69.9839,43.6521
[32m[03/26 17:22:16 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/26 17:22:16 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/26 17:22:16 d2.evaluation.testing]: [0mcopypaste: 0.0008,0.0063,0.0000,0.0001,0.0031,0.0002
Testing finished...
