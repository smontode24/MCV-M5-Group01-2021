Successfully registered 'ds_test'!
Dataset loaded...
Loading model pretrained weights...
[32m[03/26 01:34:00 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): ResNet(
    (stem): BasicStem(
      (conv1): Conv2d(
        3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
        (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
      )
    )
    (res2): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv1): Conv2d(
          64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv2): Conv2d(
          64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
        (conv3): Conv2d(
          64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
      )
    )
    (res3): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv1): Conv2d(
          256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv2): Conv2d(
          128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
        )
        (conv3): Conv2d(
          128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
      )
    )
    (res4): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
        (conv1): Conv2d(
          512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (3): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (4): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
      (5): BottleneckBlock(
        (conv1): Conv2d(
          1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv2): Conv2d(
          256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
        )
        (conv3): Conv2d(
          256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
        )
      )
    )
    (res5): Sequential(
      (0): BottleneckBlock(
        (shortcut): Conv2d(
          1024, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
        (conv1): Conv2d(
          1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (1): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
      (2): BottleneckBlock(
        (conv1): Conv2d(
          2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv2): Conv2d(
          512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2), bias=False
          (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
        )
        (conv3): Conv2d(
          512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
          (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(2048, 2048, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(2048, 15, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(2048, 60, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=100352, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        2048, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/26 01:34:49 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2642 images left.
[32m[03/26 01:34:50 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 3347         |  bicycle   | 0            |    car     | 8029         |
|            |              |            |              |            |              |
|   total    | 11376        |            |              |            |              |[0m
[32m[03/26 01:34:50 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/26 01:34:50 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/26 01:34:50 d2.data.common]: [0mSerializing 2642 elements to byte tensors and concatenating them all ...
[32m[03/26 01:34:54 d2.data.common]: [0mSerialized dataset takes 1039.45 MiB
Checkpoint loaded...
[32m[03/26 01:34:56 d2.evaluation.coco_evaluation]: [0m'ds_test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[5m[31mWARNING[0m [32m[03/26 01:34:56 d2.data.datasets.coco]: [0mUsing previously cached COCO format annotations at '/home/group01/W4_detectron2/pretrained/test_output/ds_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[32m[03/26 01:36:12 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/26 01:36:12 d2.data.common]: [0mSerializing 2642 elements to byte tensors and concatenating them all ...
[32m[03/26 01:36:16 d2.data.common]: [0mSerialized dataset takes 1039.45 MiB
[32m[03/26 01:36:18 d2.evaluation.evaluator]: [0mStart inference on 2642 images
[32m[03/26 01:36:21 d2.evaluation.evaluator]: [0mInference done 11/2642. 0.1114 s / img. ETA=0:06:17
[32m[03/26 01:36:26 d2.evaluation.evaluator]: [0mInference done 38/2642. 0.1232 s / img. ETA=0:07:47
[32m[03/26 01:36:31 d2.evaluation.evaluator]: [0mInference done 62/2642. 0.1278 s / img. ETA=0:08:14
[32m[03/26 01:36:36 d2.evaluation.evaluator]: [0mInference done 85/2642. 0.1299 s / img. ETA=0:08:31
[32m[03/26 01:36:44 d2.evaluation.evaluator]: [0mInference done 109/2642. 0.1311 s / img. ETA=0:09:41
[32m[03/26 01:36:49 d2.evaluation.evaluator]: [0mInference done 133/2642. 0.1318 s / img. ETA=0:09:26
[32m[03/26 01:36:54 d2.evaluation.evaluator]: [0mInference done 157/2642. 0.1323 s / img. ETA=0:09:14
[32m[03/26 01:36:59 d2.evaluation.evaluator]: [0mInference done 181/2642. 0.1326 s / img. ETA=0:09:04
[32m[03/26 01:37:04 d2.evaluation.evaluator]: [0mInference done 206/2642. 0.1328 s / img. ETA=0:08:54
[32m[03/26 01:37:09 d2.evaluation.evaluator]: [0mInference done 232/2642. 0.1324 s / img. ETA=0:08:42
[32m[03/26 01:37:14 d2.evaluation.evaluator]: [0mInference done 259/2642. 0.1318 s / img. ETA=0:08:29
[32m[03/26 01:37:19 d2.evaluation.evaluator]: [0mInference done 284/2642. 0.1317 s / img. ETA=0:08:21
[32m[03/26 01:37:25 d2.evaluation.evaluator]: [0mInference done 309/2642. 0.1316 s / img. ETA=0:08:14
[32m[03/26 01:37:30 d2.evaluation.evaluator]: [0mInference done 333/2642. 0.1320 s / img. ETA=0:08:09
[32m[03/26 01:37:37 d2.evaluation.evaluator]: [0mInference done 356/2642. 0.1319 s / img. ETA=0:08:18
[32m[03/26 01:37:42 d2.evaluation.evaluator]: [0mInference done 381/2642. 0.1320 s / img. ETA=0:08:10
[32m[03/26 01:37:47 d2.evaluation.evaluator]: [0mInference done 407/2642. 0.1321 s / img. ETA=0:08:02
[32m[03/26 01:37:52 d2.evaluation.evaluator]: [0mInference done 434/2642. 0.1321 s / img. ETA=0:07:52
[32m[03/26 01:37:57 d2.evaluation.evaluator]: [0mInference done 468/2642. 0.1309 s / img. ETA=0:07:35
[32m[03/26 01:38:02 d2.evaluation.evaluator]: [0mInference done 495/2642. 0.1308 s / img. ETA=0:07:26
[32m[03/26 01:38:07 d2.evaluation.evaluator]: [0mInference done 527/2642. 0.1305 s / img. ETA=0:07:13
[32m[03/26 01:38:12 d2.evaluation.evaluator]: [0mInference done 558/2642. 0.1300 s / img. ETA=0:07:02
[32m[03/26 01:38:17 d2.evaluation.evaluator]: [0mInference done 587/2642. 0.1298 s / img. ETA=0:06:53
[32m[03/26 01:38:22 d2.evaluation.evaluator]: [0mInference done 621/2642. 0.1292 s / img. ETA=0:06:40
[32m[03/26 01:38:27 d2.evaluation.evaluator]: [0mInference done 659/2642. 0.1283 s / img. ETA=0:06:25
[32m[03/26 01:38:32 d2.evaluation.evaluator]: [0mInference done 700/2642. 0.1275 s / img. ETA=0:06:09
[32m[03/26 01:38:37 d2.evaluation.evaluator]: [0mInference done 741/2642. 0.1265 s / img. ETA=0:05:54
[32m[03/26 01:38:42 d2.evaluation.evaluator]: [0mInference done 778/2642. 0.1260 s / img. ETA=0:05:43
[32m[03/26 01:38:48 d2.evaluation.evaluator]: [0mInference done 811/2642. 0.1258 s / img. ETA=0:05:34
[32m[03/26 01:38:53 d2.evaluation.evaluator]: [0mInference done 845/2642. 0.1254 s / img. ETA=0:05:25
[32m[03/26 01:38:58 d2.evaluation.evaluator]: [0mInference done 879/2642. 0.1251 s / img. ETA=0:05:17
[32m[03/26 01:39:03 d2.evaluation.evaluator]: [0mInference done 914/2642. 0.1249 s / img. ETA=0:05:08
[32m[03/26 01:39:08 d2.evaluation.evaluator]: [0mInference done 954/2642. 0.1244 s / img. ETA=0:04:57
[32m[03/26 01:39:14 d2.evaluation.evaluator]: [0mInference done 985/2642. 0.1265 s / img. ETA=0:04:54
[32m[03/26 01:39:19 d2.evaluation.evaluator]: [0mInference done 1021/2642. 0.1261 s / img. ETA=0:04:45
[32m[03/26 01:39:24 d2.evaluation.evaluator]: [0mInference done 1059/2642. 0.1256 s / img. ETA=0:04:36
[32m[03/26 01:39:29 d2.evaluation.evaluator]: [0mInference done 1096/2642. 0.1253 s / img. ETA=0:04:27
[32m[03/26 01:39:34 d2.evaluation.evaluator]: [0mInference done 1133/2642. 0.1250 s / img. ETA=0:04:19
[32m[03/26 01:39:39 d2.evaluation.evaluator]: [0mInference done 1167/2642. 0.1248 s / img. ETA=0:04:12
[32m[03/26 01:39:45 d2.evaluation.evaluator]: [0mInference done 1201/2642. 0.1247 s / img. ETA=0:04:06
[32m[03/26 01:39:50 d2.evaluation.evaluator]: [0mInference done 1231/2642. 0.1246 s / img. ETA=0:04:00
[32m[03/26 01:39:55 d2.evaluation.evaluator]: [0mInference done 1259/2642. 0.1248 s / img. ETA=0:03:56
[32m[03/26 01:40:00 d2.evaluation.evaluator]: [0mInference done 1287/2642. 0.1249 s / img. ETA=0:03:52
[32m[03/26 01:40:05 d2.evaluation.evaluator]: [0mInference done 1316/2642. 0.1249 s / img. ETA=0:03:47
[32m[03/26 01:40:10 d2.evaluation.evaluator]: [0mInference done 1347/2642. 0.1248 s / img. ETA=0:03:41
[32m[03/26 01:40:15 d2.evaluation.evaluator]: [0mInference done 1381/2642. 0.1247 s / img. ETA=0:03:35
[32m[03/26 01:40:20 d2.evaluation.evaluator]: [0mInference done 1413/2642. 0.1245 s / img. ETA=0:03:29
[32m[03/26 01:40:25 d2.evaluation.evaluator]: [0mInference done 1442/2642. 0.1246 s / img. ETA=0:03:24
[32m[03/26 01:40:30 d2.evaluation.evaluator]: [0mInference done 1472/2642. 0.1245 s / img. ETA=0:03:19
[32m[03/26 01:40:35 d2.evaluation.evaluator]: [0mInference done 1513/2642. 0.1241 s / img. ETA=0:03:10
[32m[03/26 01:40:40 d2.evaluation.evaluator]: [0mInference done 1551/2642. 0.1239 s / img. ETA=0:03:03
[32m[03/26 01:40:45 d2.evaluation.evaluator]: [0mInference done 1568/2642. 0.1254 s / img. ETA=0:03:02
[32m[03/26 01:40:50 d2.evaluation.evaluator]: [0mInference done 1604/2642. 0.1252 s / img. ETA=0:02:55
[32m[03/26 01:40:55 d2.evaluation.evaluator]: [0mInference done 1640/2642. 0.1250 s / img. ETA=0:02:48
[32m[03/26 01:41:00 d2.evaluation.evaluator]: [0mInference done 1682/2642. 0.1245 s / img. ETA=0:02:40
[32m[03/26 01:41:06 d2.evaluation.evaluator]: [0mInference done 1721/2642. 0.1242 s / img. ETA=0:02:33
[32m[03/26 01:41:11 d2.evaluation.evaluator]: [0mInference done 1757/2642. 0.1241 s / img. ETA=0:02:26
[32m[03/26 01:41:16 d2.evaluation.evaluator]: [0mInference done 1783/2642. 0.1241 s / img. ETA=0:02:22
[32m[03/26 01:41:21 d2.evaluation.evaluator]: [0mInference done 1807/2642. 0.1243 s / img. ETA=0:02:19
[32m[03/26 01:41:26 d2.evaluation.evaluator]: [0mInference done 1831/2642. 0.1245 s / img. ETA=0:02:15
[32m[03/26 01:41:31 d2.evaluation.evaluator]: [0mInference done 1855/2642. 0.1247 s / img. ETA=0:02:12
[32m[03/26 01:41:36 d2.evaluation.evaluator]: [0mInference done 1879/2642. 0.1248 s / img. ETA=0:02:08
[32m[03/26 01:41:41 d2.evaluation.evaluator]: [0mInference done 1903/2642. 0.1250 s / img. ETA=0:02:04
[32m[03/26 01:41:46 d2.evaluation.evaluator]: [0mInference done 1929/2642. 0.1251 s / img. ETA=0:02:00
[32m[03/26 01:41:51 d2.evaluation.evaluator]: [0mInference done 1954/2642. 0.1253 s / img. ETA=0:01:56
[32m[03/26 01:41:56 d2.evaluation.evaluator]: [0mInference done 1979/2642. 0.1254 s / img. ETA=0:01:52
[32m[03/26 01:42:01 d2.evaluation.evaluator]: [0mInference done 2004/2642. 0.1255 s / img. ETA=0:01:48
[32m[03/26 01:42:06 d2.evaluation.evaluator]: [0mInference done 2030/2642. 0.1256 s / img. ETA=0:01:44
[32m[03/26 01:42:12 d2.evaluation.evaluator]: [0mInference done 2062/2642. 0.1256 s / img. ETA=0:01:39
[32m[03/26 01:42:17 d2.evaluation.evaluator]: [0mInference done 2069/2642. 0.1275 s / img. ETA=0:01:38
[32m[03/26 01:42:22 d2.evaluation.evaluator]: [0mInference done 2105/2642. 0.1273 s / img. ETA=0:01:32
[32m[03/26 01:42:27 d2.evaluation.evaluator]: [0mInference done 2137/2642. 0.1272 s / img. ETA=0:01:26
[32m[03/26 01:42:32 d2.evaluation.evaluator]: [0mInference done 2162/2642. 0.1273 s / img. ETA=0:01:22
[32m[03/26 01:42:37 d2.evaluation.evaluator]: [0mInference done 2187/2642. 0.1274 s / img. ETA=0:01:18
[32m[03/26 01:42:42 d2.evaluation.evaluator]: [0mInference done 2212/2642. 0.1275 s / img. ETA=0:01:14
[32m[03/26 01:42:47 d2.evaluation.evaluator]: [0mInference done 2237/2642. 0.1276 s / img. ETA=0:01:10
[32m[03/26 01:42:52 d2.evaluation.evaluator]: [0mInference done 2262/2642. 0.1277 s / img. ETA=0:01:06
[32m[03/26 01:42:57 d2.evaluation.evaluator]: [0mInference done 2287/2642. 0.1279 s / img. ETA=0:01:01
[32m[03/26 01:43:03 d2.evaluation.evaluator]: [0mInference done 2312/2642. 0.1280 s / img. ETA=0:00:57
[32m[03/26 01:43:08 d2.evaluation.evaluator]: [0mInference done 2337/2642. 0.1281 s / img. ETA=0:00:53
[32m[03/26 01:43:13 d2.evaluation.evaluator]: [0mInference done 2374/2642. 0.1279 s / img. ETA=0:00:46
[32m[03/26 01:43:18 d2.evaluation.evaluator]: [0mInference done 2410/2642. 0.1277 s / img. ETA=0:00:40
[32m[03/26 01:43:23 d2.evaluation.evaluator]: [0mInference done 2445/2642. 0.1276 s / img. ETA=0:00:34
[32m[03/26 01:43:28 d2.evaluation.evaluator]: [0mInference done 2478/2642. 0.1275 s / img. ETA=0:00:28
[32m[03/26 01:43:33 d2.evaluation.evaluator]: [0mInference done 2511/2642. 0.1274 s / img. ETA=0:00:22
[32m[03/26 01:43:38 d2.evaluation.evaluator]: [0mInference done 2546/2642. 0.1272 s / img. ETA=0:00:16
[32m[03/26 01:43:43 d2.evaluation.evaluator]: [0mInference done 2579/2642. 0.1272 s / img. ETA=0:00:10
[32m[03/26 01:43:48 d2.evaluation.evaluator]: [0mInference done 2608/2642. 0.1271 s / img. ETA=0:00:05
[32m[03/26 01:43:53 d2.evaluation.evaluator]: [0mInference done 2637/2642. 0.1271 s / img. ETA=0:00:00
[32m[03/26 01:43:54 d2.evaluation.evaluator]: [0mTotal inference time: 0:07:34.203821 (0.172243 s / img per device, on 1 devices)
[32m[03/26 01:43:54 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:05:35 (0.127135 s / img per device, on 1 devices)
[32m[03/26 01:43:56 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/26 01:43:56 d2.evaluation.coco_evaluation]: [0mSaving results to /home/group01/W4_detectron2/pretrained/test_output/coco_instances_results.json
[32m[03/26 01:43:57 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.14s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 3.70 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.30 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.560
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.822
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.620
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.575
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.698
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.448
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.193
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.639
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.664
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.629
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.816
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.978
[32m[03/26 01:44:01 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 56.004 | 82.201 | 61.965 | 57.521 | 69.848 | 44.828 |
[32m[03/26 01:44:01 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP   | category   | AP     |
|:-----------|:-------|:-----------|:-----|:-----------|:-------|
| person     | 45.641 | bicycle    | nan  | car        | 66.367 |
Loading and preparing results...
DONE (t=1.66s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 10.93 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.29 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.001
[32m[03/26 01:44:20 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.001 | 0.009  | 0.000  | 0.000 | 0.003 | 0.000 |
[32m[03/26 01:44:20 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| person     | 0.000 | bicycle    | nan  | car        | 0.003 |
[32m[03/26 01:44:20 d2.engine.defaults]: [0mEvaluation results for ds_test in csv format:
[32m[03/26 01:44:20 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/26 01:44:20 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/26 01:44:20 d2.evaluation.testing]: [0mcopypaste: 56.0043,82.2011,61.9653,57.5213,69.8480,44.8284
[32m[03/26 01:44:20 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/26 01:44:20 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/26 01:44:20 d2.evaluation.testing]: [0mcopypaste: 0.0013,0.0095,0.0000,0.0001,0.0029,0.0003
Testing finished...
