Successfully registered 'ds_test'!
Dataset loaded...
Loading model pretrained weights...
[32m[03/26 01:33:44 d2.engine.defaults]: [0mModel:
GeneralizedRCNN(
  (backbone): FPN(
    (fpn_lateral2): Conv2d(256, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral3): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral4): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (fpn_lateral5): Conv2d(2048, 256, kernel_size=(1, 1), stride=(1, 1))
    (fpn_output5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (top_block): LastLevelMaxPool()
    (bottom_up): ResNet(
      (stem): BasicStem(
        (conv1): Conv2d(
          3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False
          (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
        )
      )
      (res2): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv1): Conv2d(
            64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv2): Conv2d(
            64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=64, eps=1e-05)
          )
          (conv3): Conv2d(
            64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
        )
      )
      (res3): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv1): Conv2d(
            256, 128, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv2): Conv2d(
            128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=128, eps=1e-05)
          )
          (conv3): Conv2d(
            128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
        )
      )
      (res4): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
          (conv1): Conv2d(
            512, 256, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (3): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (4): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
        (5): BottleneckBlock(
          (conv1): Conv2d(
            1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv2): Conv2d(
            256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=256, eps=1e-05)
          )
          (conv3): Conv2d(
            256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=1024, eps=1e-05)
          )
        )
      )
      (res5): Sequential(
        (0): BottleneckBlock(
          (shortcut): Conv2d(
            1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
          (conv1): Conv2d(
            1024, 512, kernel_size=(1, 1), stride=(2, 2), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (1): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
        (2): BottleneckBlock(
          (conv1): Conv2d(
            2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv2): Conv2d(
            512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=512, eps=1e-05)
          )
          (conv3): Conv2d(
            512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False
            (norm): FrozenBatchNorm2d(num_features=2048, eps=1e-05)
          )
        )
      )
    )
  )
  (proposal_generator): RPN(
    (rpn_head): StandardRPNHead(
      (conv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
      (objectness_logits): Conv2d(256, 3, kernel_size=(1, 1), stride=(1, 1))
      (anchor_deltas): Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))
    )
    (anchor_generator): DefaultAnchorGenerator(
      (cell_anchors): BufferList()
    )
  )
  (roi_heads): StandardROIHeads(
    (box_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(7, 7), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(7, 7), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(7, 7), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(7, 7), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (box_head): FastRCNNConvFCHead(
      (flatten): Flatten(start_dim=1, end_dim=-1)
      (fc1): Linear(in_features=12544, out_features=1024, bias=True)
      (fc_relu1): ReLU()
      (fc2): Linear(in_features=1024, out_features=1024, bias=True)
      (fc_relu2): ReLU()
    )
    (box_predictor): FastRCNNOutputLayers(
      (cls_score): Linear(in_features=1024, out_features=81, bias=True)
      (bbox_pred): Linear(in_features=1024, out_features=320, bias=True)
    )
    (mask_pooler): ROIPooler(
      (level_poolers): ModuleList(
        (0): ROIAlign(output_size=(14, 14), spatial_scale=0.25, sampling_ratio=0, aligned=True)
        (1): ROIAlign(output_size=(14, 14), spatial_scale=0.125, sampling_ratio=0, aligned=True)
        (2): ROIAlign(output_size=(14, 14), spatial_scale=0.0625, sampling_ratio=0, aligned=True)
        (3): ROIAlign(output_size=(14, 14), spatial_scale=0.03125, sampling_ratio=0, aligned=True)
      )
    )
    (mask_head): MaskRCNNConvUpsampleHead(
      (mask_fcn1): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn2): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn3): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (mask_fcn4): Conv2d(
        256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1)
        (activation): ReLU()
      )
      (deconv): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))
      (deconv_relu): ReLU()
      (predictor): Conv2d(256, 80, kernel_size=(1, 1), stride=(1, 1))
    )
  )
)
[32m[03/26 01:34:37 d2.data.build]: [0mRemoved 0 images with no usable annotations. 2642 images left.
[32m[03/26 01:34:37 d2.data.build]: [0mDistribution of instances among all 3 categories:
[36m|  category  | #instances   |  category  | #instances   |  category  | #instances   |
|:----------:|:-------------|:----------:|:-------------|:----------:|:-------------|
|   person   | 3347         |  bicycle   | 0            |    car     | 8029         |
|            |              |            |              |            |              |
|   total    | 11376        |            |              |            |              |[0m
[32m[03/26 01:34:37 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in training: [ResizeShortestEdge(short_edge_length=(640, 672, 704, 736, 768, 800), max_size=1333, sample_style='choice'), RandomFlip()]
[32m[03/26 01:34:37 d2.data.build]: [0mUsing training sampler TrainingSampler
[32m[03/26 01:34:37 d2.data.common]: [0mSerializing 2642 elements to byte tensors and concatenating them all ...
[32m[03/26 01:34:43 d2.data.common]: [0mSerialized dataset takes 1039.45 MiB
Checkpoint loaded...
[32m[03/26 01:34:46 d2.evaluation.coco_evaluation]: [0m'ds_test' is not registered by `register_coco_instances`. Therefore trying to convert it to COCO format ...
[5m[31mWARNING[0m [32m[03/26 01:34:46 d2.data.datasets.coco]: [0mUsing previously cached COCO format annotations at '/home/group01/W4_detectron2/pretrained/test_output/ds_test_coco_format.json'. You need to clear the cache file if your dataset has been modified.
[32m[03/26 01:36:00 d2.data.dataset_mapper]: [0m[DatasetMapper] Augmentations used in inference: [ResizeShortestEdge(short_edge_length=(800, 800), max_size=1333, sample_style='choice')]
[32m[03/26 01:36:00 d2.data.common]: [0mSerializing 2642 elements to byte tensors and concatenating them all ...
[32m[03/26 01:36:06 d2.data.common]: [0mSerialized dataset takes 1039.45 MiB
[32m[03/26 01:36:07 d2.evaluation.evaluator]: [0mStart inference on 2642 images
[32m[03/26 01:36:10 d2.evaluation.evaluator]: [0mInference done 11/2642. 0.0550 s / img. ETA=0:03:07
[32m[03/26 01:36:15 d2.evaluation.evaluator]: [0mInference done 64/2642. 0.0613 s / img. ETA=0:04:01
[32m[03/26 01:36:20 d2.evaluation.evaluator]: [0mInference done 102/2642. 0.0652 s / img. ETA=0:04:35
[32m[03/26 01:36:25 d2.evaluation.evaluator]: [0mInference done 148/2642. 0.0656 s / img. ETA=0:04:30
[32m[03/26 01:36:30 d2.evaluation.evaluator]: [0mInference done 199/2642. 0.0653 s / img. ETA=0:04:18
[32m[03/26 01:36:35 d2.evaluation.evaluator]: [0mInference done 223/2642. 0.0766 s / img. ETA=0:04:43
[32m[03/26 01:36:40 d2.evaluation.evaluator]: [0mInference done 273/2642. 0.0741 s / img. ETA=0:04:30
[32m[03/26 01:36:45 d2.evaluation.evaluator]: [0mInference done 320/2642. 0.0727 s / img. ETA=0:04:23
[32m[03/26 01:36:50 d2.evaluation.evaluator]: [0mInference done 371/2642. 0.0714 s / img. ETA=0:04:12
[32m[03/26 01:36:55 d2.evaluation.evaluator]: [0mInference done 426/2642. 0.0702 s / img. ETA=0:04:00
[32m[03/26 01:37:00 d2.evaluation.evaluator]: [0mInference done 473/2642. 0.0710 s / img. ETA=0:03:55
[32m[03/26 01:37:05 d2.evaluation.evaluator]: [0mInference done 526/2642. 0.0704 s / img. ETA=0:03:46
[32m[03/26 01:37:10 d2.evaluation.evaluator]: [0mInference done 567/2642. 0.0711 s / img. ETA=0:03:44
[32m[03/26 01:37:15 d2.evaluation.evaluator]: [0mInference done 609/2642. 0.0718 s / img. ETA=0:03:42
[32m[03/26 01:37:20 d2.evaluation.evaluator]: [0mInference done 659/2642. 0.0721 s / img. ETA=0:03:35
[32m[03/26 01:37:25 d2.evaluation.evaluator]: [0mInference done 725/2642. 0.0716 s / img. ETA=0:03:22
[32m[03/26 01:37:30 d2.evaluation.evaluator]: [0mInference done 783/2642. 0.0711 s / img. ETA=0:03:14
[32m[03/26 01:37:35 d2.evaluation.evaluator]: [0mInference done 831/2642. 0.0711 s / img. ETA=0:03:09
[32m[03/26 01:37:40 d2.evaluation.evaluator]: [0mInference done 880/2642. 0.0712 s / img. ETA=0:03:03
[32m[03/26 01:37:45 d2.evaluation.evaluator]: [0mInference done 924/2642. 0.0717 s / img. ETA=0:03:00
[32m[03/26 01:37:51 d2.evaluation.evaluator]: [0mInference done 984/2642. 0.0716 s / img. ETA=0:02:51
[32m[03/26 01:37:56 d2.evaluation.evaluator]: [0mInference done 1046/2642. 0.0709 s / img. ETA=0:02:43
[32m[03/26 01:38:01 d2.evaluation.evaluator]: [0mInference done 1109/2642. 0.0703 s / img. ETA=0:02:34
[32m[03/26 01:38:06 d2.evaluation.evaluator]: [0mInference done 1139/2642. 0.0723 s / img. ETA=0:02:34
[32m[03/26 01:38:11 d2.evaluation.evaluator]: [0mInference done 1194/2642. 0.0718 s / img. ETA=0:02:28
[32m[03/26 01:38:16 d2.evaluation.evaluator]: [0mInference done 1251/2642. 0.0713 s / img. ETA=0:02:21
[32m[03/26 01:38:21 d2.evaluation.evaluator]: [0mInference done 1306/2642. 0.0708 s / img. ETA=0:02:15
[32m[03/26 01:38:26 d2.evaluation.evaluator]: [0mInference done 1361/2642. 0.0704 s / img. ETA=0:02:09
[32m[03/26 01:38:31 d2.evaluation.evaluator]: [0mInference done 1415/2642. 0.0701 s / img. ETA=0:02:03
[32m[03/26 01:38:36 d2.evaluation.evaluator]: [0mInference done 1468/2642. 0.0698 s / img. ETA=0:01:57
[32m[03/26 01:38:41 d2.evaluation.evaluator]: [0mInference done 1538/2642. 0.0692 s / img. ETA=0:01:49
[32m[03/26 01:38:46 d2.evaluation.evaluator]: [0mInference done 1602/2642. 0.0687 s / img. ETA=0:01:42
[32m[03/26 01:38:51 d2.evaluation.evaluator]: [0mInference done 1669/2642. 0.0683 s / img. ETA=0:01:34
[32m[03/26 01:38:56 d2.evaluation.evaluator]: [0mInference done 1743/2642. 0.0677 s / img. ETA=0:01:26
[32m[03/26 01:39:01 d2.evaluation.evaluator]: [0mInference done 1795/2642. 0.0676 s / img. ETA=0:01:21
[32m[03/26 01:39:06 d2.evaluation.evaluator]: [0mInference done 1830/2642. 0.0678 s / img. ETA=0:01:18
[32m[03/26 01:39:11 d2.evaluation.evaluator]: [0mInference done 1847/2642. 0.0678 s / img. ETA=0:01:18
[32m[03/26 01:39:16 d2.evaluation.evaluator]: [0mInference done 1889/2642. 0.0679 s / img. ETA=0:01:14
[32m[03/26 01:39:21 d2.evaluation.evaluator]: [0mInference done 1934/2642. 0.0678 s / img. ETA=0:01:10
[32m[03/26 01:39:26 d2.evaluation.evaluator]: [0mInference done 1978/2642. 0.0678 s / img. ETA=0:01:06
[32m[03/26 01:39:32 d2.evaluation.evaluator]: [0mInference done 2027/2642. 0.0677 s / img. ETA=0:01:01
[32m[03/26 01:39:37 d2.evaluation.evaluator]: [0mInference done 2086/2642. 0.0675 s / img. ETA=0:00:55
[32m[03/26 01:39:42 d2.evaluation.evaluator]: [0mInference done 2139/2642. 0.0674 s / img. ETA=0:00:50
[32m[03/26 01:39:47 d2.evaluation.evaluator]: [0mInference done 2180/2642. 0.0674 s / img. ETA=0:00:46
[32m[03/26 01:39:52 d2.evaluation.evaluator]: [0mInference done 2220/2642. 0.0674 s / img. ETA=0:00:42
[32m[03/26 01:39:57 d2.evaluation.evaluator]: [0mInference done 2260/2642. 0.0675 s / img. ETA=0:00:38
[32m[03/26 01:40:02 d2.evaluation.evaluator]: [0mInference done 2300/2642. 0.0675 s / img. ETA=0:00:34
[32m[03/26 01:40:07 d2.evaluation.evaluator]: [0mInference done 2321/2642. 0.0674 s / img. ETA=0:00:32
[32m[03/26 01:40:12 d2.evaluation.evaluator]: [0mInference done 2377/2642. 0.0673 s / img. ETA=0:00:27
[32m[03/26 01:40:17 d2.evaluation.evaluator]: [0mInference done 2437/2642. 0.0672 s / img. ETA=0:00:20
[32m[03/26 01:40:22 d2.evaluation.evaluator]: [0mInference done 2489/2642. 0.0671 s / img. ETA=0:00:15
[32m[03/26 01:40:27 d2.evaluation.evaluator]: [0mInference done 2538/2642. 0.0672 s / img. ETA=0:00:10
[32m[03/26 01:40:32 d2.evaluation.evaluator]: [0mInference done 2591/2642. 0.0671 s / img. ETA=0:00:05
[32m[03/26 01:40:37 d2.evaluation.evaluator]: [0mInference done 2640/2642. 0.0670 s / img. ETA=0:00:00
[32m[03/26 01:40:38 d2.evaluation.evaluator]: [0mTotal inference time: 0:04:28.717174 (0.101903 s / img per device, on 1 devices)
[32m[03/26 01:40:38 d2.evaluation.evaluator]: [0mTotal inference pure compute time: 0:02:56 (0.066993 s / img per device, on 1 devices)
[32m[03/26 01:40:39 d2.evaluation.coco_evaluation]: [0mPreparing results for COCO format ...
[32m[03/26 01:40:39 d2.evaluation.coco_evaluation]: [0mSaving results to /home/group01/W4_detectron2/pretrained/test_output/coco_instances_results.json
[32m[03/26 01:40:39 d2.evaluation.coco_evaluation]: [0mEvaluating predictions with unofficial COCO API...
Loading and preparing results...
DONE (t=0.10s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *bbox*
COCOeval_opt.evaluate() finished in 0.97 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.23 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.588
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.830
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.673
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.603
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.700
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.437
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.199
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.672
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.695
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.668
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.810
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.780
[32m[03/26 01:40:41 d2.evaluation.coco_evaluation]: [0mEvaluation results for bbox: 
|   AP   |  AP50  |  AP75  |  APs   |  APm   |  APl   |
|:------:|:------:|:------:|:------:|:------:|:------:|
| 58.753 | 82.974 | 67.293 | 60.336 | 69.984 | 43.652 |
[32m[03/26 01:40:41 d2.evaluation.coco_evaluation]: [0mPer-category bbox AP: 
| category   | AP     | category   | AP   | category   | AP     |
|:-----------|:-------|:-----------|:-----|:-----------|:-------|
| person     | 47.615 | bicycle    | nan  | car        | 69.891 |
Loading and preparing results...
DONE (t=1.05s)
creating index...
index created!
Running per image evaluation...
Evaluate annotation type *segm*
COCOeval_opt.evaluate() finished in 11.82 seconds.
Accumulating evaluation results...
COCOeval_opt.accumulate() finished in 0.22 seconds.
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.75      | area=   all | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.000
 Average Precision  (AP) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=  1 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets= 10 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=   all | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= small | maxDets=100 ] = 0.000
 Average Recall     (AR) @[ IoU=0.50:0.95 | area=medium | maxDets=100 ] = 0.001
 Average Recall     (AR) @[ IoU=0.50:0.95 | area= large | maxDets=100 ] = 0.000
[32m[03/26 01:41:00 d2.evaluation.coco_evaluation]: [0mEvaluation results for segm: 
|  AP   |  AP50  |  AP75  |  APs  |  APm  |  APl  |
|:-----:|:------:|:------:|:-----:|:-----:|:-----:|
| 0.001 | 0.006  | 0.000  | 0.000 | 0.003 | 0.000 |
[32m[03/26 01:41:00 d2.evaluation.coco_evaluation]: [0mPer-category segm AP: 
| category   | AP    | category   | AP   | category   | AP    |
|:-----------|:------|:-----------|:-----|:-----------|:------|
| person     | 0.000 | bicycle    | nan  | car        | 0.002 |
[32m[03/26 01:41:00 d2.engine.defaults]: [0mEvaluation results for ds_test in csv format:
[32m[03/26 01:41:00 d2.evaluation.testing]: [0mcopypaste: Task: bbox
[32m[03/26 01:41:00 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/26 01:41:00 d2.evaluation.testing]: [0mcopypaste: 58.7529,82.9742,67.2928,60.3358,69.9839,43.6521
[32m[03/26 01:41:00 d2.evaluation.testing]: [0mcopypaste: Task: segm
[32m[03/26 01:41:00 d2.evaluation.testing]: [0mcopypaste: AP,AP50,AP75,APs,APm,APl
[32m[03/26 01:41:00 d2.evaluation.testing]: [0mcopypaste: 0.0008,0.0063,0.0000,0.0001,0.0031,0.0002
Testing finished...
